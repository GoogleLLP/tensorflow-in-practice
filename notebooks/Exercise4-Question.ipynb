{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UncprnB0ymAE"
   },
   "source": [
    "Below is code with a link to a happy or sad dataset which contains 80 images, 40 happy and 40 sad. \n",
    "Create a convolutional neural network that trains to 100% accuracy on these images,  which cancels training upon hitting training accuracy of >.999\n",
    "\n",
    "Hint -- it will work best with 3 convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "import os\n",
    "import zipfile\n",
    "from os import path, getcwd, chdir\n",
    "\n",
    "# DO NOT CHANGE THE LINE BELOW. If you are developing in a local\n",
    "# environment, then grab happy-or-sad.zip from the Coursera Jupyter Notebook\n",
    "# and place it inside a local folder and edit the path to that location\n",
    "path = f\"{getcwd()}/../tmp2/happy-or-sad.zip\"\n",
    "\n",
    "zip_ref = zipfile.ZipFile(path, 'r')\n",
    "zip_ref.extractall(\"/tmp/h-or-s\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_happy_sad_model\n",
    "def train_happy_sad_model():\n",
    "    # Please write your code only where you are indicated.\n",
    "    # please do not remove # model fitting inline comments.\n",
    "\n",
    "    DESIRED_ACCURACY = 0.999\n",
    "\n",
    "    class myCallback(Callback):\n",
    "         # Your Code\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            \"\"\"\n",
    "            early stop\\n\n",
    "            :param epoch: 轮数\n",
    "            :param logs: 日志\n",
    "            :return: 空\n",
    "            \"\"\"\n",
    "            if logs[\"acc\"] > DESIRED_ACCURACY:\n",
    "                print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "    callbacks = [myCallback()]\n",
    "    \n",
    "    # This Code Block should Define and Compile the Model. Please assume the images are 150 X 150 in your implementation.\n",
    "    model = tf.keras.models.Sequential([\n",
    "        # Your Code Here\n",
    "        Conv2D(filters=16, kernel_size=(3, 3), activation=\"relu\", input_shape=(150, 150, 3), name=\"conv2d_1\"),\n",
    "        MaxPool2D(pool_size=(2, 2), data_format=\"channels_last\", name=\"pool2d_1\"),\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\", name=\"conv2d_2\"),\n",
    "        MaxPool2D(pool_size=(2, 2), data_format=\"channels_last\", name=\"pool2d_2\"),\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", name=\"conv2d_3\"),\n",
    "        MaxPool2D(pool_size=(2, 2), data_format=\"channels_last\", name=\"pool2d_3\"),\n",
    "        Flatten(data_format=\"channels_last\", name=\"flatten_4\"),\n",
    "        Dense(units=512, activation=\"relu\", name=\"dense_4\"),\n",
    "        Dense(units=1, activation=\"sigmoid\", name=\"dense_5\")\n",
    "    ])\n",
    "\n",
    "    from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "    model.compile(\n",
    "        # Your Code Here #\n",
    "        optimizer=RMSprop(lr=0.001),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "        \n",
    "\n",
    "    # This code block should create an instance of an ImageDataGenerator called train_datagen \n",
    "    # And a train_generator by calling train_datagen.flow_from_directory\n",
    "\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "    train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "    # Please use a target_size of 150 X 150.\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        # Your Code Here\n",
    "        directory=\"/tmp/h-or-s\",\n",
    "        target_size=(150, 150),\n",
    "        class_mode=\"binary\",\n",
    "        batch_size=32\n",
    "    )\n",
    "    # Expected output: 'Found 80 images belonging to 2 classes'\n",
    "\n",
    "    # This code block should call model.fit_generator and train for\n",
    "    # a number of epochs.\n",
    "    # model fitting\n",
    "    history = model.fit_generator(\n",
    "        # Your Code Here\n",
    "        generator=train_generator,\n",
    "        epochs=20,\n",
    "        workers=-1,\n",
    "        use_multiprocessing=True,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    # model fitting\n",
    "    return history.history['acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0104 15:07:11.323026 140317423142720 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0104 15:07:11.527923 140317423142720 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 7s 2s/step - loss: 3.3516 - acc: 0.4250\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.6842 - acc: 0.5250\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.6193 - acc: 0.7125\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.6263 - acc: 0.6375\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.4290 - acc: 0.8750\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.6719 - acc: 0.6000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2884 - acc: 0.8875\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2587 - acc: 0.8250\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1509 - acc: 0.9375\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1292 - acc: 0.9625\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0741 - acc: 0.9750\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1828 - acc: 0.9250\n",
      "Epoch 13/20\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0692 - acc: 1.0000\n",
      "Reached 99.9% accuracy so cancelling training!\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0628 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Expected output: \"Reached 99.9% accuracy so cancelling training!\"\"\n",
    "train_happy_sad_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now click the 'Submit Assignment' button above.\n",
    "# Once that is complete, please run the following two cells to save your work and close the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Save the notebook -->\n",
    "IPython.notebook.save_checkpoint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.session.delete();\n",
    "window.onbeforeunload = null\n",
    "setTimeout(function() { window.close(); }, 1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "introduction-tensorflow",
   "graded_item_id": "1kAlw",
   "launcher_item_id": "PNLYD"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
